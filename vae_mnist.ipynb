{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Variational Autoencoder (VAE) for MNIST Dataset\n",
                "\n",
                "In this notebook, we implement a Variational Autoencoder (VAE) using TensorFlow/Keras.\n",
                "We use the MNIST dataset to train our model, visualize the reconstructed images, and explore the latent space."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers\n",
                "from tensorflow.keras.datasets import mnist\n",
                "from tensorflow.keras.models import Model\n",
                "from tensorflow.keras import backend as K"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dfd0d86b",
            "metadata": {},
            "source": [
                "### VariationalAutoencoder class\n",
                "The VariationalAutoencoder class encapsulates the entire VAE architecture, from building the encoder and decoder to training and visualization. It's structured to facilitate easy experimentation and understanding of Variational Autoencoders, particularly applied to the MNIST dataset in this example.\n",
                "\n",
                "Let's break down the `VariationalAutoencoder` class step by step, explaining each method and its purpose:\n",
                "\n",
                "### 1. `__init__` Method\n",
                "\n",
                "```python\n",
                "    def __init__(self, input_shape=(784,), latent_dim=2, intermediate_dim=512):\n",
                "        self.input_shape = input_shape\n",
                "        self.latent_dim = latent_dim\n",
                "        self.intermediate_dim = intermediate_dim\n",
                "        self.encoder = self.build_encoder()\n",
                "        self.decoder = self.build_decoder()\n",
                "        self.vae = self.build_vae()\n",
                "```\n",
                "\n",
                "- **Purpose**: This method initializes the VAE with specified dimensions and builds its encoder, decoder, and VAE models.\n",
                "  \n",
                "- **Parameters**:\n",
                "  - `input_shape`: Shape of the input data. Default is `(784,)` corresponding to MNIST images flattened to 784 dimensions.\n",
                "  - `latent_dim`: Dimensionality of the latent space. Default is `2` for easy visualization.\n",
                "  - `intermediate_dim`: Dimensionality of the intermediate layer in the encoder and decoder. Default is `512`.\n",
                "\n",
                "- **Attributes**:\n",
                "  - `self.input_shape`: Stores the input shape.\n",
                "  - `self.latent_dim`: Stores the dimensionality of the latent space.\n",
                "  - `self.intermediate_dim`: Stores the dimensionality of the intermediate layer.\n",
                "  - `self.encoder`: Instance of the encoder model.\n",
                "  - `self.decoder`: Instance of the decoder model.\n",
                "  - `self.vae`: Instance of the VAE model.\n",
                "\n",
                "### 2. `build_encoder` Method\n",
                "\n",
                "```python\n",
                "    def build_encoder(self):\n",
                "        inputs = keras.Input(shape=self.input_shape)\n",
                "        h = layers.Dense(self.intermediate_dim, activation='relu')(inputs)\n",
                "        z_mean = layers.Dense(self.latent_dim)(h)\n",
                "        z_log_var = layers.Dense(self.latent_dim)(h)\n",
                "\n",
                "        def sampling(args):\n",
                "            z_mean, z_log_var = args\n",
                "            epsilon = K.random_normal(shape=(K.shape(z_mean)[0], self.latent_dim), mean=0., stddev=1.)\n",
                "            return z_mean + K.exp(z_log_var / 2) * epsilon\n",
                "\n",
                "        z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
                "        return Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
                "```\n",
                "\n",
                "- **Purpose**: Constructs the encoder model which maps inputs to the latent space (`z_mean`, `z_log_var`, `z`).\n",
                "\n",
                "- **Details**:\n",
                "  - `inputs`: Defines the input layer with shape `self.input_shape`.\n",
                "  - `h`: Hidden layer of the encoder with `self.intermediate_dim` units and ReLU activation.\n",
                "  - `z_mean`: Dense layer outputs the mean of the latent space.\n",
                "  - `z_log_var`: Dense layer outputs the log variance of the latent space.\n",
                "  - `sampling`: Lambda layer for sampling latent space points based on the reparameterization trick.\n",
                "  - `z`: Outputs the sampled latent space points.\n",
                "\n",
                "### 3. `build_decoder` Method\n",
                "\n",
                "```python\n",
                "    def build_decoder(self):\n",
                "        latent_inputs = keras.Input(shape=(self.latent_dim,))\n",
                "        h_decoded = layers.Dense(self.intermediate_dim, activation='relu')(latent_inputs)\n",
                "        x_decoded_mean = layers.Dense(self.input_shape[0], activation='sigmoid')(h_decoded)\n",
                "        return Model(latent_inputs, x_decoded_mean, name='decoder')\n",
                "```\n",
                "\n",
                "- **Purpose**: Constructs the decoder model which reconstructs inputs from the latent space.\n",
                "\n",
                "- **Details**:\n",
                "  - `latent_inputs`: Defines the input layer for the latent space points with shape `(self.latent_dim,)`.\n",
                "  - `h_decoded`: Hidden layer of the decoder with `self.intermediate_dim` units and ReLU activation.\n",
                "  - `x_decoded_mean`: Outputs the reconstructed data with `self.input_shape[0]` units and sigmoid activation.\n",
                "\n",
                "### 4. `build_vae` Method\n",
                "\n",
                "```python\n",
                "    def build_vae(self):\n",
                "        input_x = keras.Input(shape=self.input_shape)\n",
                "        z_mean, z_log_var, z = self.encoder(input_x)\n",
                "        reconstructed_x = self.decoder(z)\n",
                "        vae = Model(input_x, reconstructed_x, name='vae')\n",
                "\n",
                "        # Add KL divergence regularization loss\n",
                "        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
                "        vae.add_loss(K.mean(kl_loss))\n",
                "\n",
                "        return vae\n",
                "```\n",
                "\n",
                "- **Purpose**: Constructs the VAE model which combines the encoder and decoder.\n",
                "\n",
                "- **Details**:\n",
                "  - `input_x`: Input layer for the original data.\n",
                "  - `z_mean`, `z_log_var`, `z`: Outputs of the encoder.\n",
                "  - `reconstructed_x`: Outputs of the decoder, reconstructing the input.\n",
                "  - `vae`: Model that takes `input_x` and outputs `reconstructed_x`.\n",
                "  - Adds a KL divergence regularization loss to the VAE model to ensure the latent space distribution is close to a standard normal distribution.\n",
                "\n",
                "### 5. `compile` Method\n",
                "\n",
                "```python\n",
                "    def compile(self, optimizer='adam', loss='binary_crossentropy'):\n",
                "        self.vae.compile(optimizer=optimizer, loss=loss)\n",
                "```\n",
                "\n",
                "- **Purpose**: Compiles the VAE model with specified optimizer and loss function.\n",
                "\n",
                "- **Parameters**:\n",
                "  - `optimizer`: Optimizer algorithm to use during training. Default is `'adam'`.\n",
                "  - `loss`: Loss function to minimize during training. Default is `'binary_crossentropy'`.\n",
                "\n",
                "### 6. `train` Method\n",
                "\n",
                "```python\n",
                "    def train(self, x_train, x_test, epochs=50, batch_size=128):\n",
                "        history = self.vae.fit(x_train, x_train,\n",
                "                               epochs=epochs,\n",
                "                               batch_size=batch_size,\n",
                "                               validation_data=(x_test, x_test))\n",
                "        return history\n",
                "```\n",
                "\n",
                "- **Purpose**: Trains the VAE model on given training data.\n",
                "\n",
                "- **Parameters**:\n",
                "  - `x_train`: Training data.\n",
                "  - `x_test`: Validation data.\n",
                "  - `epochs`: Number of training epochs. Default is `50`.\n",
                "  - `batch_size`: Batch size for training. Default is `128`.\n",
                "\n",
                "- **Returns**: Training history which includes loss and metrics values.\n",
                "\n",
                "### 7. `plot_results` Method\n",
                "\n",
                "```python\n",
                "    def plot_results(self, x_test, n=10):\n",
                "        decoded_imgs = self.vae.predict(x_test)\n",
                "\n",
                "        plt.figure(figsize=(20, 4))\n",
                "        for i in range(n):\n",
                "            # Display original images\n",
                "            ax = plt.subplot(2, n, i + 1)\n",
                "            plt.imshow(x_test[i].reshape(28, 28))\n",
                "            plt.gray()\n",
                "            ax.get_xaxis().set_visible(False)\n",
                "            ax.get_yaxis().set_visible(False)\n",
                "\n",
                "            # Display reconstructed images\n",
                "            ax = plt.subplot(2, n, i + 1 + n)\n",
                "            plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
                "            plt.gray()\n",
                "            ax.get_xaxis().set_visible(False)\n",
                "            ax.get_yaxis().set_visible(False)\n",
                "        plt.show()\n",
                "```\n",
                "\n",
                "- **Purpose**: Plots original and reconstructed images to visualize model performance.\n",
                "\n",
                "- **Parameters**:\n",
                "  - `x_test`: Test data used for plotting.\n",
                "  - `n`: Number of samples to display. Default is `10`.\n",
                "\n",
                "- **Details**:\n",
                "  - `decoded_imgs`: Reconstructed images obtained by predicting on `x_test`.\n",
                "  - Displays a grid of `n` original images followed by their corresponding reconstructions using Matplotlib.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define Variational Autoencoder (VAE) class\n",
                "class VariationalAutoencoder:\n",
                "    def __init__(self, input_shape=(784,), latent_dim=2, intermediate_dim=512):\n",
                "        self.input_shape = input_shape\n",
                "        self.latent_dim = latent_dim\n",
                "        self.intermediate_dim = intermediate_dim\n",
                "        self.encoder = self.build_encoder()\n",
                "        self.decoder = self.build_decoder()\n",
                "        self.vae = self.build_vae()\n",
                "\n",
                "    def build_encoder(self):\n",
                "        inputs = keras.Input(shape=self.input_shape)\n",
                "        h = layers.Dense(self.intermediate_dim, activation='relu')(inputs)\n",
                "        z_mean = layers.Dense(self.latent_dim)(h)\n",
                "        z_log_var = layers.Dense(self.latent_dim)(h)\n",
                "\n",
                "        def sampling(args):\n",
                "            z_mean, z_log_var = args\n",
                "            epsilon = K.random_normal(shape=(K.shape(z_mean)[0], self.latent_dim), mean=0., stddev=1.)\n",
                "            return z_mean + K.exp(z_log_var / 2) * epsilon\n",
                "\n",
                "        z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
                "        return Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
                "\n",
                "    def build_decoder(self):\n",
                "        latent_inputs = keras.Input(shape=(self.latent_dim,))\n",
                "        h_decoded = layers.Dense(self.intermediate_dim, activation='relu')(latent_inputs)\n",
                "        x_decoded_mean = layers.Dense(self.input_shape[0], activation='sigmoid')(h_decoded)\n",
                "        return Model(latent_inputs, x_decoded_mean, name='decoder')\n",
                "\n",
                "    def build_vae(self):\n",
                "        input_x = keras.Input(shape=self.input_shape)\n",
                "        z_mean, z_log_var, z = self.encoder(input_x)\n",
                "        reconstructed_x = self.decoder(z)\n",
                "        vae = Model(input_x, reconstructed_x, name='vae')\n",
                "\n",
                "        # Add KL divergence regularization loss\n",
                "        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
                "        vae.add_loss(K.mean(kl_loss))\n",
                "\n",
                "        return vae\n",
                "\n",
                "    def compile(self, optimizer='adam', loss='binary_crossentropy'):\n",
                "        self.vae.compile(optimizer=optimizer, loss=loss)\n",
                "\n",
                "    def train(self, x_train, x_test, epochs=50, batch_size=128):\n",
                "        history = self.vae.fit(x_train, x_train,\n",
                "                               epochs=epochs,\n",
                "                               batch_size=batch_size,\n",
                "                               validation_data=(x_test, x_test))\n",
                "        return history\n",
                "\n",
                "    def plot_results(self, x_test, n=10):\n",
                "        decoded_imgs = self.vae.predict(x_test)\n",
                "\n",
                "        plt.figure(figsize=(20, 4))\n",
                "        for i in range(n):\n",
                "            # Display original images\n",
                "            ax = plt.subplot(2, n, i + 1)\n",
                "            plt.imshow(x_test[i].reshape(28, 28))\n",
                "            plt.gray()\n",
                "            ax.get_xaxis().set_visible(False)\n",
                "            ax.get_yaxis().set_visible(False)\n",
                "\n",
                "            # Display reconstructed images\n",
                "            ax = plt.subplot(2, n, i + 1 + n)\n",
                "            plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
                "            plt.gray()\n",
                "            ax.get_xaxis().set_visible(False)\n",
                "            ax.get_yaxis().set_visible(False)\n",
                "        plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3bb4b9c2",
            "metadata": {},
            "source": [
                "### Data Loading and Preprocessing Explanation\n",
                "\n",
                "```python\n",
                "# Load MNIST dataset\n",
                "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
                "\n",
                "# Normalize pixel values between 0 and 1\n",
                "x_train = x_train.astype('float32') / 255.\n",
                "x_test = x_test.astype('float32') / 255.\n",
                "\n",
                "# Flatten images into 784-dimensional vectors (28x28)\n",
                "image_size = x_train.shape[1]\n",
                "original_dim = image_size * image_size\n",
                "x_train = np.reshape(x_train, [-1, original_dim])\n",
                "x_test = np.reshape(x_test, [-1, original_dim])\n",
                "```\n",
                "\n",
                "#### Step-by-Step Explanation:\n",
                "\n",
                "1. **Loading the MNIST Dataset**:\n",
                "   - `mnist.load_data()`: This function is provided by TensorFlow/Keras and retrieves the MNIST dataset split into training and test sets.\n",
                "   - **Outputs**:\n",
                "     - `(x_train, y_train)`: Training images (`x_train`) and corresponding labels (`y_train`).\n",
                "     - `(x_test, y_test)`: Test images (`x_test`) and corresponding labels (`y_test`).\n",
                "\n",
                "2. **Normalizing Pixel Values**:\n",
                "   - `x_train = x_train.astype('float32') / 255.`: Converts the pixel values of the training images to floats and normalizes them between 0 and 1 by dividing by 255.\n",
                "   - `x_test = x_test.astype('float32') / 255.`: Similarly, normalizes the pixel values of the test images.\n",
                "\n",
                "3. **Flattening Images**:\n",
                "   - **Why Flatten?**: In the MNIST dataset, each image is originally a 28x28 pixel grid. To feed these images into a fully connected neural network (as required by the VAE architecture), we flatten each image into a single 784-dimensional vector.\n",
                "   - **Reshape Operation**:\n",
                "     - `image_size = x_train.shape[1]`: Retrieves the size of each image dimension (28 for MNIST).\n",
                "     - `original_dim = image_size * image_size`: Calculates the total number of pixels per image (784 for MNIST).\n",
                "     - `x_train = np.reshape(x_train, [-1, original_dim])`: Reshapes the training images (`x_train`) into a 2D array where each row represents one flattened image.\n",
                "     - `x_test = np.reshape(x_test, [-1, original_dim])`: Reshapes the test images (`x_test`) similarly.\n",
                "\n",
                "#### Summary:\n",
                "\n",
                "- **Dataset Loading**: Loads the MNIST dataset using TensorFlow/Keras utility functions, providing training and test sets of images and labels.\n",
                "- **Normalization**: Converts pixel values from integers (0 to 255) to floats between 0 and 1, aiding model convergence during training.\n",
                "- **Flattening**: Transforms each 28x28 image into a flat vector of 784 elements, preparing the data for input into the VAE's fully connected layers.\n",
                "\n",
                "This preprocessing step ensures that the data is in a suitable format and range for training the Variational Autoencoder on the MNIST dataset. It's a crucial initial step in any machine learning pipeline to prepare data for model training and evaluation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load and preprocess MNIST dataset\n",
                "(x_train, _), (x_test, _) = mnist.load_data()\n",
                "x_train = x_train.astype('float32') / 255.\n",
                "x_test = x_test.astype('float32') / 255.\n",
                "x_train = np.reshape(x_train, [-1, 784])\n",
                "x_test = np.reshape(x_test, [-1, 784])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "738f4d95",
            "metadata": {},
            "source": [
                "### 1. Instantiation of VAE Model\n",
                "\n",
                "```python\n",
                "# Instantiate VAE model\n",
                "vae = VariationalAutoencoder(input_shape=(784,), latent_dim=2, intermediate_dim=512)\n",
                "```\n",
                "\n",
                "#### Explanation:\n",
                "\n",
                "- **Purpose**: The instantiation step creates an instance of the `VariationalAutoencoder` class, which encapsulates the entire VAE architecture, including the encoder, decoder, and the VAE model itself.\n",
                "  \n",
                "- **Parameters**:\n",
                "  - `input_shape`: Specifies the shape of the input data. Here, it's `(784,)`, corresponding to the flattened MNIST images.\n",
                "  - `latent_dim`: Defines the dimensionality of the latent space. In this case, it's `2` for easy visualization.\n",
                "  - `intermediate_dim`: Determines the size of the intermediate layer in the encoder and decoder. The default is `512`.\n",
                "\n",
                "- **Instance Attributes**:\n",
                "  - `vae.encoder`: Instance of the encoder model, responsible for mapping inputs to the latent space.\n",
                "  - `vae.decoder`: Instance of the decoder model, responsible for reconstructing inputs from the latent space.\n",
                "  - `vae.vae`: Instance of the combined VAE model, which integrates both encoder and decoder.\n",
                "\n",
                "### 2. Compiling the VAE Model\n",
                "\n",
                "```python\n",
                "# Compile VAE model\n",
                "vae.compile(optimizer='adam', loss='binary_crossentropy')\n",
                "```\n",
                "\n",
                "#### Explanation:\n",
                "\n",
                "- **Purpose**: The compilation step configures the VAE model for training by specifying the optimizer and loss function.\n",
                "\n",
                "- **Parameters**:\n",
                "  - `optimizer`: Specifies the optimization algorithm to use during training. Here, `'adam'` is a popular choice due to its efficiency and effectiveness for a wide range of problems.\n",
                "  - `loss`: Defines the loss function to minimize during training. `'binary_crossentropy'` is appropriate for binary classification tasks, which aligns with the reconstruction objective of the VAE.\n",
                "\n",
                "- **Compilation Details**:\n",
                "  - `vae.compile(optimizer='adam', loss='binary_crossentropy')`: Configures the VAE model with the Adam optimizer and binary cross-entropy loss. This setup is standard for VAEs aiming to reconstruct input data while regularizing the latent space distribution.\n",
                "\n",
                "### 3. Training the VAE Model\n",
                "\n",
                "```python\n",
                "# Train the VAE model\n",
                "history = vae.train(x_train, x_test, epochs=50, batch_size=128)\n",
                "```\n",
                "\n",
                "#### Explanation:\n",
                "\n",
                "- **Purpose**: The training step fits the VAE model to the training data (`x_train`) and evaluates its performance on the validation data (`x_test`).\n",
                "\n",
                "- **Parameters**:\n",
                "  - `x_train`: Training data, consisting of flattened MNIST images.\n",
                "  - `x_test`: Validation data, used to monitor model performance during training.\n",
                "  - `epochs`: Number of training epochs. Each epoch represents one complete pass through the entire dataset. Here, `epochs=50` specifies training for 50 iterations over the dataset.\n",
                "  - `batch_size`: Number of samples per gradient update. Larger batch sizes can speed up training but require more memory.\n",
                "\n",
                "- **Returns**:\n",
                "  - `history`: Training history object containing recorded loss and metric values for each epoch.\n",
                "\n",
                "#### Training Workflow:\n",
                "\n",
                "- The `vae.train` method executes the training loop, optimizing the VAE model parameters based on the specified optimizer and loss function.\n",
                "- During each epoch, the model computes gradients, updates weights, and evaluates performance on both training and validation data.\n",
                "- `history` object captures and stores training metrics such as loss values, allowing analysis and visualization of model performance over time.\n",
                "\n",
                "### Summary:\n",
                "\n",
                "- **Instantiation**: Creates an instance of the `VariationalAutoencoder` class, initializing the VAE model architecture.\n",
                "- **Compilation**: Configures the VAE model with an optimizer (`'adam'`) and a loss function (`'binary_crossentropy'`), preparing it for training.\n",
                "- **Training**: Fits the VAE model to the MNIST dataset, optimizing model parameters (`weights`) to minimize reconstruction error while regularizing the latent space distribution.\n",
                "\n",
                "These steps collectively enable the training of a Variational Autoencoder on the MNIST dataset, facilitating both image reconstruction and latent space exploration for generative modeling tasks. Each step plays a crucial role in constructing, optimizing, and evaluating the performance of the VAE model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Instantiate VAE model\n",
                "vae = VariationalAutoencoder(input_shape=(784,), latent_dim=2, intermediate_dim=512)\n",
                "\n",
                "# Compile VAE model\n",
                "vae.compile(optimizer='adam', loss='binary_crossentropy')\n",
                "\n",
                "# Train VAE model\n",
                "history = vae.train(x_train, x_test, epochs=50, batch_size=128)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot results (original vs reconstructed images)\n",
                "vae.plot_results(x_test)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
